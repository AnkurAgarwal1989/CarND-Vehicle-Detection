{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from features import extract_features, calc_hog_features, calc_bin_spatial_features\n",
    "from skimage.util.shape import view_as_windows\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dist_pickle = pickle.load( open('Car_NoCar_LinearSVC.p', 'r' ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orientations\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"color_spatial_size\"]\n",
    "h_colorspace = dist_pickle[\"h_colorspace\"]\n",
    "s_colorspace = dist_pickle[\"s_colorspace\"]\n",
    "#hog_channel = dist_pickle[\"hog_channel\"]\n",
    "hog_channel = 'ALL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we will be using the same indexing of windows for all images. The data changes, but our indices will not\n",
    "#Pre make this list. Consumes memory, but saves time\n",
    "def get_hog_features_(hog_data, patch_size=64, orient=9, channels=3, pix_per_cell=8, cell_per_block=2, cells_per_step=4):\n",
    "    ncells = (patch_size - 8)//8 + 1\n",
    "    nblocks = (ncells - cell_per_block)//1 + 1\n",
    "    window_shape = (channels, nblocks, nblocks, cell_per_block, cell_per_block, orient)\n",
    "    step = cells_per_step\n",
    "    feature_vector_len = (channels * nblocks**2 * cell_per_block**2 * orient)\n",
    "    hog_windows = view_as_windows(hog_data, window_shape, step)\n",
    "    hog_feature_array = hog_windows.reshape(-1, feature_vector_len)\n",
    "    print(\"Hog feature array shape: \", hog_feature_array.shape)\n",
    "    return hog_feature_array\n",
    "\n",
    "#Input is an image scaled by 0.5\n",
    "def get_color_spatial_features_(color_data, patch_size=32, channels=3, pixels_per_step=16):\n",
    "    #1 cell = 8 pixels for full scale image. Here we use 0.5 scale.\n",
    "    window_shape = (patch_size, patch_size, channels)\n",
    "    feature_vector_len = (patch_size**2 * channels)\n",
    "    step = pixels_per_step\n",
    "    color_spatial_windows = view_as_windows(color_data, window_shape, step)\n",
    "    color_spatial_feature_array = color_spatial_windows.reshape(-1, feature_vector_len)\n",
    "    print(\"Color Spatial array shape: \", color_spatial_feature_array.shape)\n",
    "    return color_spatial_feature_array    \n",
    "\n",
    "def get_feature_array(img_roi, hog_channel, h_cspace, s_space, patch_size=64, orient=9,\n",
    "                      pix_per_cell=8, cell_per_block=2, cells_per_step=4, pixels_per_step=16):\n",
    "    hog_data = calc_hog_features(img_roi, orient, pix_per_cell, cell_per_block, \n",
    "                                 channel=hog_channel, cspace=h_cspace, vis=False, feature_vec=False)\n",
    "    #hog_data = np.array(hog_data)\n",
    "    print(\"Hog data shape\", hog_data.shape)\n",
    "    hog_feature_array = get_hog_features_(hog_data, patch_size, orient, 3, pix_per_cell, cell_per_block, cells_per_step)\n",
    "    \n",
    "    \n",
    "    color_data = calc_bin_spatial_features(img_roi, cspace=s_space, scale=2, feature_vec=False)\n",
    "    color_spatial_feature_array = get_color_spatial_features_(color_data, patch_size=32, channels=3, pixels_per_step=pixels_per_step)\n",
    "    \n",
    "    feature_array = np.hstack((hog_feature_array, color_spatial_feature_array))\n",
    "    print(\"Entire feature Array \", feature_array.shape)\n",
    "    return feature_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, \n",
    "              spatial_size, cells_per_step, hog_channel='ALL', show_windows=True):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    img_roi = img[ystart:ystop,:,:]\n",
    "    #ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if scale != 1:\n",
    "        imshape = img_roi.shape\n",
    "        img_roi = cv2.resize(img_roi, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "    x_size = img_roi.shape[1]\n",
    "    y_size = img_roi.shape[0]\n",
    "    print(x_size, y_size)\n",
    "    fa = get_feature_array(img_roi, hog_channel, h_cspace=h_colorspace, s_space=s_colorspace)\n",
    "    print(fa.shape)\n",
    "    return fa\n",
    "    # Define blocks and steps as above\n",
    "    #Number of Cells\n",
    "    nxcells = x_size // pix_per_cell\n",
    "    nycells = y_size // pix_per_cell\n",
    "    #Number of Blocks\n",
    "    nxblocks = (nxcells - cell_per_block) + 1 ##(W-F)/S + 1, W=ncells, F=cell_per_block, S=Stride=1\n",
    "    nyblocks = (nycells - cell_per_block) + 1 \n",
    "    #nxblocks = (x_size // pix_per_cell)-1  \n",
    "    #nyblocks = (y_size // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient * (cell_per_block**2)\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = ((window // pix_per_cell) - cell_per_block) + 1\n",
    "    \n",
    "    #We have 8 cells per 64 pixels\n",
    "    #Each cell step (8 pixels), refers to a move of 1/8 or overlap of 7/8=87.5% overlap\n",
    "    #A step of 2 cells, means we slide windows by 16 pixels, overlap of 75%.\n",
    "    #cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    #Number of steps we can take over HoG array\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog_array = extract_features(img_roi, h_cspace=h_colorspace, s_cspace=s_colorspace, orient=orient, \n",
    "                           pix_per_cell=pix_per_cell, cell_per_block=cell_per_block,\n",
    "                           hog_channel=hog_channel, feature_vec=False, vis=False)\n",
    "    #The hog_array we get has a shape 3XnyblocksXnxblocksXcell_per_blockXcell_per_blockXorientations\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "            # Extract HOG for this patch\n",
    "            hog_features = hog_array[:, ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "            \n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "            # Extract the image patch\n",
    "            subimg = cv2.resize(img_roi[ytop:ytop+window, xleft:xleft+window, :], (64,64))\n",
    "            \n",
    "            # Get color features\n",
    "            spatial_features = calc_bin_spatial_features(subimg, s_colorspace)\n",
    "            #hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "            \n",
    "            if show_windows:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                color = np.random.randint(0, 256, (3,))\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart), \n",
    "                              (xbox_left+win_draw, ytop_draw+win_draw+ystart),color,6) \n",
    "            # Scale features and make a prediction\n",
    "            test_features = X_scaler.transform(np.hstack((hog_features, spatial_features)).reshape(1, -1))\n",
    "            #test_features = X_scaler.transform(hog_features.reshape(1,-1))\n",
    "            #test_features = X_scaler.transform(np.hstack((shape_feat, hist_feat)).reshape(1, -1))    \n",
    "            test_prediction = svc.predict(test_features)\n",
    "            \n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                #color = np.random.randint(0, 256, (3,))\n",
    "                cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),\n",
    "                              (xbox_left+win_draw, ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "             \n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(738L, 1280L, 3L)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('test_images/test8.jpg') \n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_cars_1(img):\n",
    "    window = 64\n",
    "    ystart = 400\n",
    "    ystop = ystart + (window*3)\n",
    "    scale = 1 #aSteps 5\n",
    "    t1 = time.time()\n",
    "    out_img = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell,\n",
    "                        cell_per_block, spatial_size, cells_per_step=5, hog_channel=hog_channel, show_windows=False)\n",
    "    return out_img\n",
    "#print(\"Time taken\", time.time()-t1)\n",
    "#plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5292"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*7*2*2*9*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128L, 128L)\n",
      "('Hog data shape', (3L, 15L, 15L, 2L, 2L, 9L))\n",
      "('Hog feature array shape: ', (9L, 5292L))\n",
      "('Color Spatial array shape: ', (9L, 3072L))\n",
      "('Entire feature Array ', (9L, 8364L))\n",
      "(9L, 8364L)\n"
     ]
    }
   ],
   "source": [
    "fa = find_cars_1(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_cars_2(img):\n",
    "    ystart = 400 + (window)\n",
    "    ystop = ystart + (window*6)\n",
    "    scale = 1.8 #steps 4\n",
    "\n",
    "    t1 = time.time()\n",
    "    out_img = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell,\n",
    "                        cell_per_block, spatial_size, cells_per_step=6, hog_channel=hog_channel, show_windows=False)\n",
    "    #print(\"Time taken\", time.time()-t1)\n",
    "    return out_img\n",
    "#plt.imshow(cv2.cvtColor(out_img, cv2.COLOR_BGR2RGB))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine(img1, img2):\n",
    "    return (cv2.addWeighted(img1, 0.5, img2, 0.5, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64L, 64L)\n",
      "('Hog data shape', (3L, 7L, 7L, 2L, 2L, 9L))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`window_shape` is too large",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-f503d46c769f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Time taken '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_cars_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_cars_2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;31m#print(f1.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-97a712a76159>\u001b[0m in \u001b[0;36mfind_cars_1\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     out_img = find_cars(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell,\n\u001b[1;32m----> 8\u001b[1;33m                         cell_per_block, spatial_size, cells_per_step=5, hog_channel=hog_channel, show_windows=False)\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout_img\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#print(\"Time taken\", time.time()-t1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-c87dc88a009a>\u001b[0m in \u001b[0;36mfind_cars\u001b[1;34m(img, ystart, ystop, scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, spatial_size, cells_per_step, hog_channel, show_windows)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0my_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_roi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mfa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_feature_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_roi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhog_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_cspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mh_colorspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms_space\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms_colorspace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-8cc3cf8ee946>\u001b[0m in \u001b[0;36mget_feature_array\u001b[1;34m(img_roi, hog_channel, h_cspace, s_space, patch_size, orient, pix_per_cell, cell_per_block, cells_per_step, pixels_per_step)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;31m#hog_data = np.array(hog_data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hog data shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhog_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mhog_feature_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_hog_features_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhog_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpix_per_cell\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell_per_block\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcells_per_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-8cc3cf8ee946>\u001b[0m in \u001b[0;36mget_hog_features_\u001b[1;34m(hog_data, patch_size, orient, channels, pix_per_cell, cell_per_block, cells_per_step)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcells_per_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mfeature_vector_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mchannels\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnblocks\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mcell_per_block\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0morient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mhog_windows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mview_as_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhog_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mhog_feature_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhog_windows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_vector_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hog feature array shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhog_feature_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ankura\\AppData\\Local\\Continuum\\Anaconda2\\lib\\site-packages\\skimage\\util\\shape.pyc\u001b[0m in \u001b[0;36mview_as_windows\u001b[1;34m(arr_in, window_shape, step)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_shape\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mwindow_shape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`window_shape` is too large\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow_shape\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: `window_shape` is too large"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture('project_video.mp4')\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "recorder = cv2.VideoWriter('out.mp4', fourcc, 30, (1280, 720))\n",
    "t1 = time.time()\n",
    "cnt = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cnt+=1;\n",
    "        #print(\"cnt\", cnt)\n",
    "        if cnt == 300:\n",
    "            break\n",
    "        if cnt%10 == 0:\n",
    "            print('Time taken ', time.time()-t1)\n",
    "        f1 = find_cars_1(frame)\n",
    "        f2 = find_cars_2(frame)\n",
    "        #print(f1.shape)\n",
    "        #print(f2.shape)\n",
    "        img_boxes = combine(find_cars_1(frame), find_cars_2(frame))\n",
    "        recorder.write(img_boxes)\n",
    "    else:\n",
    "        break\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "print('Time taken ', time.time()-t1)\n",
    "cap.release()\n",
    "recorder.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
